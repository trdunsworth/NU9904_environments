{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single, plot_next_multi\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATSx, TSMixerx\n",
    "\n",
    "from neuralforecast.losses.numpy import mae, mse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = pd.read_csv('~/envs/uni2ts/data/month_clean.csv')\n",
    "week = pd.read_csv('~/envs/uni2ts/data/week_clean.csv')\n",
    "day = pd.read_csv('~/envs/uni2ts/data/day_clean.csv')\n",
    "hour = pd.read_csv('~/envs/uni2ts/data/hour_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "m_date_range = pd.date_range(start=month.iloc[0]['ds'], end=month.iloc[-1]['ds'], freq='D')\n",
    "w_date_range = pd.date_range(start=week.iloc[0]['ds'], end=week.iloc[-1]['ds'], freq='D')\n",
    "d_date_range = pd.date_range(start=day.iloc[0]['ds'], end=day.iloc[-1]['ds'], freq='D')\n",
    "h_date_range = pd.date_range(start=hour.iloc[0]['ds'], end=hour.iloc[-1]['ds'], freq='D')\n",
    "\n",
    "us_holidays = holidays.US()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_owa(model_sMAPE, model_MASE, naive_sMAPE, naive_MASE):\n",
    "    owa = 0.5 * ((model_sMAPE / naive_sMAPE) + (model_MASE / naive_MASE))\n",
    "    return owa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month.insert(0, 'unique_id', 'M')\n",
    "week.insert(0, 'unique_id', 'W')\n",
    "day.insert(0, 'unique_id', 'D')\n",
    "hour.insert(0, 'unique_id', 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour.insert(0, 'unique_id', 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alxm = pd.DataFrame(month, columns=['unique_id', 'ds', 'alx'])\n",
    "alxm.rename(columns={'alx':'y'}, inplace=True)\n",
    "alxm['is_holiday'] = alxm['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "alxm['ds'] = pd.to_datetime(alxm['ds'])\n",
    "tr_alxm = alxm[:48]\n",
    "ts_alxm = alxm[48:]\n",
    "\n",
    "gcom = pd.DataFrame(month, columns=['unique_id', 'ds', 'gco'])\n",
    "gcom.rename(columns={'gco':'y'}, inplace=True)\n",
    "gcom['is_holiday'] = gcom['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "gcom['ds'] = pd.to_datetime(gcom['ds'])\n",
    "tr_gcom = gcom[:48]\n",
    "ts_gcom = gcom[48:]\n",
    "\n",
    "mcom = pd.DataFrame(month, columns=['unique_id', 'ds', 'mco'])\n",
    "mcom.rename(columns={'mco':'y'}, inplace=True)\n",
    "mcom['is_holiday'] = mcom['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "mcom['ds'] = pd.to_datetime(mcom['ds'])\n",
    "tr_mcom = mcom[:48] \n",
    "ts_mcom = mcom[48:]\n",
    "\n",
    "alxw = pd.DataFrame(week, columns=['unique_id', 'ds', 'alx'])\n",
    "alxw.rename(columns={'alx':'y'}, inplace=True)\n",
    "alxw['is_holiday'] = alxw['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "alxw['ds'] = pd.to_datetime(alxw['ds'])\n",
    "tr_alxw = alxw[:209]\n",
    "ts_alxw = alxw[209:]\n",
    "\n",
    "gcow = pd.DataFrame(week, columns=['unique_id', 'ds', 'gco'])\n",
    "gcow.rename(columns={'gco':'y'}, inplace=True)\n",
    "gcow['is_holiday'] = gcow['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "gcow['ds'] = pd.to_datetime(gcow['ds'])\n",
    "tr_gcow = gcow[:209]\n",
    "ts_gcow = gcow[209:]\n",
    "\n",
    "mcow = pd.DataFrame(week, columns=['unique_id', 'ds', 'mco'])\n",
    "mcow.rename(columns={'mco':'y'}, inplace=True)\n",
    "mcow['is_holiday'] = mcow['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "mcow['ds'] = pd.to_datetime(mcow['ds'])\n",
    "tr_mcow = mcow[:209]\n",
    "ts_mcow = mcow[209:]\n",
    "\n",
    "alxd = pd.DataFrame(day, columns=['unique_id', 'ds', 'alx'])\n",
    "alxd.rename(columns={'alx':'y'}, inplace=True)\n",
    "alxd['is_holiday'] = alxd['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "alxd['ds'] = pd.to_datetime(alxd['ds'])\n",
    "tr_alxd = alxd[:365]\n",
    "ts_alxd = alxd[365:]\n",
    "\n",
    "gcod = pd.DataFrame(day, columns=['unique_id', 'ds', 'gco'])\n",
    "gcod.rename(columns={'gco':'y'}, inplace=True)\n",
    "gcod['is_holiday'] = gcod['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "gcod['ds'] = pd.to_datetime(gcod['ds'])\n",
    "tr_gcod = gcod[:365]\n",
    "ts_gcod = gcod[365:]\n",
    "\n",
    "mcod = pd.DataFrame(day, columns=['unique_id', 'ds', 'mco'])\n",
    "mcod.rename(columns={'mco':'y'}, inplace=True)\n",
    "mcod['is_holiday'] = mcod['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "mcod['ds'] = pd.to_datetime(mcod['ds'])\n",
    "tr_mcod = mcod[:365]\n",
    "ts_mcod = mcod[365:]\n",
    "\n",
    "alxh = pd.DataFrame(hour, columns=['unique_id', 'ds', 'alx'])\n",
    "alxh.rename(columns={'alx':'y'}, inplace=True)\n",
    "alxh['is_holiday'] = alxh['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "alxh['ds'] = pd.to_datetime(alxh['ds'])\n",
    "tr_alxh = alxh[:2184]\n",
    "ts_alxh = alxh[2184:]\n",
    "\n",
    "gcoh = pd.DataFrame(hour, columns=['unique_id', 'ds', 'gco'])\n",
    "gcoh.rename(columns={'gco':'y'}, inplace=True)\n",
    "gcoh['is_holiday'] = gcoh['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "gcoh['ds'] = pd.to_datetime(gcoh['ds'])\n",
    "tr_gcoh = gcoh[:2184]\n",
    "ts_gcoh = gcoh[2184:]\n",
    "\n",
    "mcoh = pd.DataFrame(hour, columns=['unique_id', 'ds', 'mco'])\n",
    "mcoh.rename(columns={'mco':'y'}, inplace=True)\n",
    "mcoh['is_holiday'] = mcoh['ds'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "mcoh['ds'] = pd.to_datetime(mcoh['ds'])\n",
    "tr_mcoh = mcoh[:2184]\n",
    "ts_mcoh = mcoh[2184:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moirai_alxm = alxm.set_index('ds')\n",
    "moirai_gcom = gcom.set_index('ds')\n",
    "moirai_mcom = mcom.set_index('ds')\n",
    "moirai_alxw = alxw.set_index('ds')\n",
    "moirai_gcow = gcow.set_index('ds')\n",
    "moirai_mcow = mcow.set_index('ds')\n",
    "moirai_alxd = alxd.set_index('ds')\n",
    "moirai_gcod = gcod.set_index('ds')\n",
    "moirai_mocd = mcod.set_index('ds')\n",
    "moirai_alxh = alxh.set_index('ds')\n",
    "moirai_gcoh = gcoh.set_index('ds')\n",
    "moirai_mcoh = mcoh.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_and_ci(data, horizon, id, confidence=0.80):\n",
    "    n_samples, n_timesteps = data.shape\n",
    "\n",
    "    # Calculate the median for each timestep\n",
    "    medians = np.median(data, axis=0)\n",
    "\n",
    "    # Calculate teh lower and upper percentail for the given confidence interval\n",
    "    lower_percentile = (1 - confidence) / 2 * 100\n",
    "    upper_percentile = (1 + confidence) / 2 * 100\n",
    "\n",
    "    # Calculate the lower and upper bounds for each timestep\n",
    "    lower_bounds = np.percentile(data, lower_percentile, axis=0)\n",
    "    upper_bounds = np.percentile(data, upper_percentile, axis=0)\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    df = pd.DataFrame({\n",
    "        'unique_id': id,\n",
    "        'Moriai': medians,\n",
    "        f'Moirai-lo-{int(confidence*100)}': lower_bounds,\n",
    "        f'Moirai-hi-{int(confidence*100)}': upper_bounds\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MoiraiModule.__init__() missing 7 required positional arguments: 'distr_output', 'd_model', 'num_layers', 'patch_sizes', 'max_seq_len', 'attn_dropout_p', and 'dropout_p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m tr_alxm_ds, ts_alxm_ds \u001b[38;5;241m=\u001b[39m split(\n",
      "\u001b[1;32m     12\u001b[0m     alxm_ds, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mtest_size\n",
      "\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[1;32m     15\u001b[0m ts_alxm_data \u001b[38;5;241m=\u001b[39m ts_alxm_ds\u001b[38;5;241m.\u001b[39mgenerate_instances(\n",
      "\u001b[1;32m     16\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39mhorizon,\n",
      "\u001b[1;32m     17\u001b[0m     windows\u001b[38;5;241m=\u001b[39mtest_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mhorizon,\n",
      "\u001b[1;32m     18\u001b[0m     distance\u001b[38;5;241m=\u001b[39mhorizon\n",
      "\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[1;32m     21\u001b[0m alxm_model \u001b[38;5;241m=\u001b[39m MoiraiForecast(\n",
      "\u001b[0;32m---> 22\u001b[0m     module\u001b[38;5;241m=\u001b[39m\u001b[43mMoiraiModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalesforecs/moirai-1.0-R-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n",
      "\u001b[1;32m     23\u001b[0m     prediction_length\u001b[38;5;241m=\u001b[39mhorizon,\n",
      "\u001b[1;32m     24\u001b[0m     context_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n",
      "\u001b[1;32m     25\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m     26\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n",
      "\u001b[1;32m     27\u001b[0m     target_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n",
      "\u001b[1;32m     28\u001b[0m     feat_dynamic_real_dim\u001b[38;5;241m=\u001b[39malxm_ds\u001b[38;5;241m.\u001b[39mnum_feat_dynamic_real,\n",
      "\u001b[1;32m     29\u001b[0m     past_feat_dynamic_real_dim\u001b[38;5;241m=\u001b[39malxm_ds\u001b[38;5;241m.\u001b[39mnum_past_feat_dynamic_real\n",
      "\u001b[1;32m     30\u001b[0m )\n",
      "\u001b[1;32m     32\u001b[0m alxm_predictor \u001b[38;5;241m=\u001b[39m alxm_model\u001b[38;5;241m.\u001b[39mcreate_predictor(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[1;32m     33\u001b[0m alxm_forecasts \u001b[38;5;241m=\u001b[39m alxm_predictor\u001b[38;5;241m.\u001b[39mpredict(ts_alxm_ds\u001b[38;5;241m.\u001b[39minput)\n",
      "\n",
      "File \u001b[0;32m~/envs/uni2ts/venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n",
      "\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/envs/uni2ts/venv/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:569\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n",
      "\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_hub_mixin_inject_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n",
      "\u001b[1;32m    567\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n",
      "\u001b[0;32m--> 569\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# Implicitly set the config as instance attribute if not already set by the class\u001b[39;00m\n",
      "\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\u001b[39;00m\n",
      "\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hub_mixin_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, {})):\n",
      "\n",
      "File \u001b[0;32m~/envs/uni2ts/venv/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:789\u001b[0m, in \u001b[0;36mPyTorchModelHubMixin._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n",
      "\u001b[1;32m    772\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n",
      "\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pretrained\u001b[39m(\n",
      "\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n",
      "\u001b[1;32m    787\u001b[0m ):\n",
      "\u001b[1;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 789\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(model_id):\n",
      "\u001b[1;32m    791\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading weights from local directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: MoiraiModule.__init__() missing 7 required positional arguments: 'distr_output', 'd_model', 'num_layers', 'patch_sizes', 'max_seq_len', 'attn_dropout_p', and 'dropout_p'"
     ]
    }
   ],
   "source": [
    "alxm_ds = PandasDataset.from_long_dataframe(\n",
    "    moirai_alxm,\n",
    "    target='y',\n",
    "    item_id='unique_id',\n",
    "    feat_dynamic_real = ['is_holiday']\n",
    "),\n",
    "\n",
    "test_size = 12\n",
    "horizon = 12\n",
    "\n",
    "tr_alxm_ds, ts_alxm_ds = split(\n",
    "    alxm_ds, offset=-test_size\n",
    ")\n",
    "\n",
    "ts_alxm_data = ts_alxm_ds.generate_instances(\n",
    "    prediction_length=horizon,\n",
    "    windows=test_size//horizon,\n",
    "    distance=horizon\n",
    ")\n",
    "\n",
    "alxm_model = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforecs/moirai-1.0-R-small\"),\n",
    "    prediction_length=horizon,\n",
    "    context_length=500,\n",
    "    patch_size=\"auto\",\n",
    "    num_samples=100,\n",
    "    target_dim=1,\n",
    "    feat_dynamic_real_dim=alxm_ds.num_feat_dynamic_real,\n",
    "    past_feat_dynamic_real_dim=alxm_ds.num_past_feat_dynamic_real\n",
    ")\n",
    "\n",
    "alxm_predictor = alxm_model.create_predictor(batch_size=32)\n",
    "alxm_forecasts = alxm_predictor.predict(ts_alxm_ds.input)\n",
    "alxm_forecasts = list(forecasts)\n",
    "\n",
    "alxm_moirai_preds = [\n",
    "    get_median_and_ci(\n",
    "        data=alxm_forecasts[i].samples,\n",
    "        horizon = horizon,\n",
    "        id = 1\n",
    "    )\n",
    "    for i in range(12)\n",
    "]\n",
    "\n",
    "alxm_moirai_preds_df = pd.concat(alxm_moirai_preds, axis=0, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
